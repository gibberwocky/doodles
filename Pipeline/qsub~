#!/bin/bash
# IEKNGHER1ujm

# To view jobs:			qstat -u dwragg
# To query error state:		qstat -j <jobid>
# To delete a job:		qdel <jobid>


# ===========
# GENOME PREP
# ===========
#PICARD="/usr/local/bioinfo/src/picard-tools/current"
#REF="/home/dwragg/save/Genomes/Amel_4.5_scaffolds"
#bwa index -a bwtsw ${REF}.fa
#samtools faidx ${REF}.fa
#java -d64 -Xmx48g -jar ${PICARD}/CreateSequenceDictionary.jar \
#  REFERENCE=${REF}.fa \
#  OUTPUT=${REF}.dict

# Location of links to paired .fastq.gz files
IN="/home/dwragg/work/Project_ROYALBEE.301/Run_Pool1.4968/RawData/"
# Read in list of files
SAMPLELIST=(${IN}*)
# Strip out the suffix
tmp1=(${SAMPLELIST[@]/_R1.fastq.gz/})
tmp2=(${tmp1[@]/_R2.fastq.gz/})
# Strip out the prefix
tmp3=(${tmp2[@]/${IN}/})
# Reduce to unique list
tmp4=( $( printf "%s\n" "${tmp3[@]}" | awk 'x[$0]++ == 0' ) )
# Iteration would commence here, or a list for qarray
SAMPLES=${tmp4[@]}

# ==============================================================================
# Mapping Loop
# ==============================================================================

# Set root paths
DUMP="/home/vignal/work/Analysis"
PIPE="/home/dwragg/work/Pipeline"

# qsub loop
for ID in ${SAMPLES[@]}
do
  mkdir -p ${DUMP}/logs/${ID}
  cd ${DUMP}
  qsub -q unlimitq -l mem=4G -l h_vmem=48G -pe parallel_smp 4 \
    -o ${DUMP}/logs/${ID} \
    -e ${DUMP}/logs/${ID} \
    ${PIPE}/map.sh -i ${PIPE}/params -p "T" -q "F" -s ${ID} -f ${IN} -o ${DUMP}
done



